{"componentChunkName":"component---src-pages-install-data-index-mdx","path":"/install/data/","result":{"pageContext":{"frontmatter":{"title":"Cloud Pak for Data 3.0.1 on IBM Managed Openshift 4.3"},"relativePagePath":"/install/data/index.mdx","titleType":"page","MdxNode":{"id":"70d6762f-5276-5dc5-b841-c265c5df5262","children":[],"parent":"ba327581-788d-5d8b-97c9-e7e2cbe81085","internal":{"content":"---\ntitle: Cloud Pak for Data 3.0.1 on IBM Managed Openshift 4.3\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\n</PageDescription>\n\n## Install Cloud Pak for Data 3.0.1 on IBM Managed Openshift 4.3\n\n<AnchorLinks>\n  <AnchorLink>Sizing Openshift Cluster for Cloud Pak for Data 3.0.1</AnchorLink>\n  <AnchorLink>Provision Openshift 4.3 Cluster on IBM Cloud</AnchorLink>\n  <AnchorLink>Setting up Openshift Cluster for Cloud Pak for Data Installation</AnchorLink>\n  <AnchorLink>Setting Portworx Storage</AnchorLink>\n  <AnchorLink>Download Installation files</AnchorLink>\n  <AnchorLink>Installing Control Plane</AnchorLink>\n  <AnchorLink>Installing Data Virtualization</AnchorLink>\n  <AnchorLink>Installing Watson Studio</AnchorLink>\n  <AnchorLink>Installing Watson Machine Learning</AnchorLink>\n  <AnchorLink>Installing Watson Openscale</AnchorLink>\n  <AnchorLink>Installing Cognos Dashboards</AnchorLink>\n  <AnchorLink>Installing Watson Knowledge Catalog</AnchorLink>\n  <AnchorLink>Installing DataStage Enterprise</AnchorLink>\n  <AnchorLink>Installing Regulatory Accelerator</AnchorLink>\n  <AnchorLink>Installing DB2 Warehouse</AnchorLink>\n  <AnchorLink>Installing DB2 Advanced Edition</AnchorLink>\n  <AnchorLink>Installing Cognos Analytics</AnchorLink>\n  <AnchorLink>Installing Watson Assistant</AnchorLink>\n  <AnchorLink>Installing Watson Discovery</AnchorLink>\n  <AnchorLink>Installing Watson Knowledge Studio</AnchorLink>\n</AnchorLinks>\n\n### Sizing Openshift Cluster for Cloud Pak for Data 3.0.1\n\nSizing Worker Nodes based on Services that are to be installed. Refer : https://salesconfig.ibmcloudpack.com/sales/#/zen/configure\nTo do the sizing\n\nPlease note that if you want to install Watson AI services (Watson Assistant, Watson Discovery, Watson AIOps, Watson Language Translator, Watson Speech to Text, Watson Text to Speech) size them separately as they will need bare metal worker nodes and will not work on virtual server worker nodes.\n\n### Provision Openshift 4.3 Cluster on IBM Cloud\n\n**Note:** Make sure you have Administrator and Manager lever permission on the account where you are provisioning the cluster.\n\nProvision Openshift 4.3 Cluster from IBM Cloud console. Select Virtual Server Worker nodes based on the above sizing calculations. If you are installing Watson AI services, we will add Bare metal worker nodes post the cluster creation.\n\n![IBM Openshift Cluster Provision](images/ProvisionCluster.png)\n\nOnce the cluster is created, create a new worker pool which will have bare metal servers required for Watson AI Services installation.\n\n![IBM Openshift Cluster Config](images/ClusterConfig.png)\n\nOnce the cluster is ready, launch its console and on the right top corner, from copy login command, get the token to login to Openshift cluster remotely using cli\n \n![IBM Openshift Cluster Config](images/CopyToken.png)\n\nMake sure you have a system with Openshift and IBM Cloud cli installed.\nhttps://cloud.ibm.com/docs/openshift?topic=openshift-openshift-cli#cli_oc\nhttps://cloud.ibm.com/docs/cli/reference/bluemix_cli/download_cli.html\n\nExecute oc login command obtained in above step from Openshift Web Console\n\n### Setting up Openshift Cluster for Cloud Pak for Data Installation\n\n1.\tCreate an external route of Openshift Image registry.\n    Use token obtained in abive step to login from a system to OpenShift Cluster and run below commands to create an external route\n\n    ```\n    oc create route reencrypt --service=image-registry -n openshift-image-registry\n    oc annotate route image-registry --overwrite haproxy.router.openshift.io/balance=source -n openshift-image-registry\n    ```\n\n2.\tResize image registry storage volume\n    Default size of Openshift image registry will not be sufficient to load images if you are going to install multiple Services on Cloud Pak for Data. Hence it needs to be resized to 200GB. Run below commands to do it.\n\n    ```\n    ibmcloud login\n    ```\n    (login into Account where your Openshift Cluster is setup)\n    ```\n    registry_pv=`oc get pvc -n openshift-image-registry | grep \"image-registry-storage\" | awk '{print $3}'`\n    volid=`oc describe pv $registry_pv -n openshift-image-registry | grep volumeId`\n    IFS='='\n    read -ra vol <<< \"$volid\"\n    volume=${vol[1]}\n    echo volume id is $volume\n    ibmcloud sl file volume-modify $volume --new-size 200 --new-tier 10 –force\n    ```\n\n3.\tSet kernel parameters (https://www.ibm.com/support/knowledgecenter/SSQNUZ_3.0.1/cpd/install/node-settings.html)\n    Since we do not have ssh access to worker nodes on ROKS, we will use daemonset to perform kernel parameter settings. Create setkernelparameters.yaml file with below contents\n\n    ```apiVersion: tuned.openshift.io/v1\n    kind: Tuned\n    metadata:\n      name: cp4d-wkc-ipc\n      namespace: openshift-cluster-node-tuning-operator\n    spec:\n      profile:\n      - name: cp4d-wkc-ipc\n        data: |\n          [main]\n          summary=Tune IPC Kernel parameters on OpenShift Worker Nodes running WKC Pods\n          [sysctl]\n          kernel.shmall = 33554432\n          kernel.shmmax = 68719476736\n          kernel.shmmni = 16384\n          kernel.sem = 250 1024000 100 16384\n          kernel.msgmax = 65536\n          kernel.msgmnb = 65536\n          kernel.msgmni = 32768\n          vm.max_map_count = 262144\n      recommend:\n      - match:\n        - label: node-role.kubernetes.io/worker\n        priority: 10\n        profile: cp4d-wkc-ipc\n    ```\n\n    Run below commands to do the changes\n\n    ```\n    oc project kube-system\n    oc create -f setkernelparameters.yaml\n    ```\n\n4.\tChange NFS mount settings\n    If you are using IBM Cloud File Storage for PVC creation, we need to make sure pvcs are mounted with root permissions. \n\n    a.\tCreate a service account called norootsquash by running the following command:\n\n    ```\n    oc create -f - << EOF\n    apiVersion: v1\n    kind: ServiceAccount\n    metadata:\n      name: norootsquash\n      namespace: kube-system\n    EOF\n    ```\n\n    b.\tGive the service account privileged security context constraints (SCC) by running the following command:\n\n    ``` \n    oc adm policy add-scc-to-user privileged system:serviceaccount:kube-system:norootsquash\n    ```\n\n    c.\tCreate the daemonset by running the following command:\n\n    ```\n    oc create -f - << EOF\n    apiVersion: apps/v1\n    kind: DaemonSet\n    metadata:\n      name: norootsquash\n      namespace: kube-system\n      labels:\n        tier: management\n        app: norootsquash\n    spec:\n      selector:\n        matchLabels:\n          name: norootsquash\n      template:\n        metadata:\n          labels:\n            name: norootsquash\n        spec:\n          serviceAccountName: norootsquash\n          initContainers:\n            - resources:\n                requests:\n                  cpu: 0.1\n              securityContext:\n                privileged: true\n              image: alpine:3.6\n              name: unrootsquash\n              command: [\"chroot\", \"/host\", \"sh\", \"-c\"]\n              args:\n                - >\n                  grep \"^Domain = slnfsv4.com\" /etc/idmapd.conf;\n                  if [ \"\\$?\" -ne \"0\" ] ; then\n                    sed -i 's/.*Domain =.*/Domain = slnfsv4.com/g' /etc/idmapd.conf;\n                    nfsidmap -c;\n                    rpc.idmapd\n                  fi;\n              volumeMounts:\n                - name: host\n                  mountPath: /host\n          containers:\n            - resources:\n                requests:\n                  cpu: 0.1\n              image: alpine:3.6\n              name: sleep\n              command: [\"/bin/sh\", \"-c\"]\n              args:\n                - >\n                  while true; do\n                    sleep 100000;\n                  done\n          volumes:\n            - hostPath:\n                path: /\n                type: Directory\n              name: host\n    EOF\n    ```\n\n### Setting Portworx Storage\n\nWatson AI services (Watson Assistant, Watson Discovery, Watson Knowledge Studio, Watson Speech to Text and Watson text to Speech) install is currently supported only with Enterprise Portworx storage. Follow the steps mentioned below to set that up for ROKS. Make sure you are logged in to IBM Cloud and Openshift using CLI (ibmcloud and oc)\n1.\tAttach Block Storage to worker nodes (https://cloud.ibm.com/docs/containers?topic=containers-utilities#block_storage_attacher)\n\n    a.\tInstall helm on your local system from where you are running the commands. (https://github.com/helm/helm/releases)\n\n    b.\tRun below command\n    ```\n    oc project kube-system\n    ```\n    c.  Below command should return 0 results\n    ```\n    oc get serviceaccount -n kube-system | grep tiller\n    ```\n    d.  Run below commands\n    ```\n    oc create serviceaccount tiller -n kube-system\n    oc create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller -n kube-system\n    oc get serviceaccount -n kube-system tiller\n    helm init --service-account tiller\n    oc get pods -n kube-system -l app=helm\n    helm repo add iks-charts https://icr.io/helm/iks-charts\n    helm repo add ibm-charts https://raw.githubusercontent.com/IBM/charts/master/repo/stable\n    helm repo add ibm-community https://raw.githubusercontent.com/IBM/charts/master/repo/community\n    helm repo add entitled https://raw.githubusercontent.com/IBM/charts/master/repo/entitled\n    helm repo update\n    helm install iks-charts/ibm-block-storage-attacher --name block-attacher\n    oc get pod -n kube-system -o wide | grep attacher\n    oc get storageclasses | grep attacher\n    mkdir cp4d\n    cd cp4d\n    git clone https://github.com/IBM/ibmcloud-storage-utilities.git\n    cd ibmcloud-storage-utilities/block-storage-provisioner\n    ```\n    e.\tvi yamlgen.yaml (provide the storage as you would need for your application, clustername and size of the block storage. Min 500 GB is required for Watson Assistant)\n        Provide the storage details i.e your Openshift Cluster name and region where it is located.\n\n    ![IBM Block Storage Provisioning](images/yamlgen.png)\n\n    f.\tCreate Classic Infrastructure Key\n\n    - On IBM Cloud Console, from menu bar select Manage -> Access\n    - Select API keys tab and from drop down select Classic Infrastructure API keys.\n    - If one is already listed, click Actions menu (3 dots) > Details\n    - Copy API username and API key\n\n    ![IBM Cloud API keys](images/CopyAPIKeys.png) \n\n    g.\texport SL_USERNAME=infrastructure username obtained in above step\n\n    h.\texport SL_API_KEY=infrastructure API key obtained in above step\n\n    i.\tEdit Dockerfile and update first line to “FROM ubuntu:18.04”\n\n    j.\tEdit px_iks_utils.py (only if you have virtual server nodes as well as bare metal nodes, this is to avoid attaching block storage on virtual server nodes). Add below line on line number 83  : ``` if re.search('m[a-z]3c', w['machineType']): ``` It should like this \n\n    ![IBM Block Storage Provisioning](images/px_iks_utils.png) Add “import re” on the top below existing import statements.\n\n    k.\tRun below commands and check for annotation ibm.io/attachstatus: attached\n    ```\n    docker build -t mkpvyaml .\n    docker run --rm -v `pwd`:/data -v ~/.bluemix:/config -e SL_API_KEY=$SL_API_KEY -e SL_USERNAME=$SL_USERNAME mkpvyaml\n    oc apply -f pv-<cluster-name>.yaml\n    oc describe pv <pvname created in above step>\n    ```\n        \n    l.\tCordon nodes which are not bare metal server with below command. Execute below command for each non bare metal node.\n    ```\n    oc adm cordon <node-name>\n    ```\n    ![IBM Block Storage Provisioning](images/CornonNodes.png)\n\n2.\tTo use internal portworx key-value database instead of etcd service, copy the imagepull secret from default to kube-system namespace.\n    ```\n    oc get secrets -n default | grep icr\n    oc get secret -n default all-icr-io -o yaml | sed 's/default/kube-system/g' | oc -n kube-system create -f -\n    oc patch -n kube-system serviceaccount/default --type='json' -p='[{\"op\":\"add\",\"path\":\"/imagePullSecrets/-\",\"value\":{\"name”:”all-icr-io\"}}]'\n    ```\n\n3.\tFrom IBM Cloud Catalog, provision “Portworx Enterprise” service. Select same region as your Openshift Cluster. Select Enterprise plan from Pricing Plan. In IBM Cloud API Key, mention same key which was used to create block storage in above steps.  Select “Portworx KVDB” from Portworx metadata key-value store dropdown.\n\n    ![IBM Portworx Service](images/PortworxService.png)\n\n4.\tCheck if portworx pods are created and up successfully.\n    ```\n    oc get pods -n kube-system | grep 'portworx\\|stork'\n    ```\n\n5.\tLogin to one of the portworx pods and list the status of your Portworx cluster\n    ```\n    PX_POD=$(oc get pods -l name=portworx -n kube-system -o jsonpath='{.items[0].metadata.name}')\n    oc exec $PX_POD -n kube-system -- /opt/pwx/bin/pxctl status\n    ```\n\n    Non-bare metal server worker nodes will be listed with No StorageNode.\n\n    ![IBM Portworx Service](images/PortworxPods.png)\n\n### Download Installation files\n\n1.\tDownload installation files from: https://github.com/IBM/cpd-cli/releases\n2.\tCopy the downloaded tar file to a system where you have setup oc cli\n3.\tExtract the contents of the tar file\n4.\tObtain your Entitlement key from : https://myibm.ibm.com/products-services/containerlibrary by logging in with you IBM ID connected with Partner World\n5.\tEdit  repo.yaml which can be found in the extracted contents of the tar file. Specify username as cp and apiKey as Entitlement Key obtained in above step.\n\n**Note :** If you are installing multiple services on your cluster, you must run the installations one at a time and wait until the installation completes before installing another service. You cannot run the installations in parallel.\n\n### Installing Control Plane\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly lite --namespace <project-name>\n    ```\n\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give any name where you will install Cloud Pak for Data Control Plane. For example:  cpd301. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly lite --namespace <project-name> --apply\n    ```\n5.\tRun the following command to grant cpd-admin-role to the project administration user:\n    ```\n    oc adm policy add-role-to-user cpd-admin-role <project_admin> --role-namespace=<project-name> -n <project-name>\n    ```\n\n    project-admin : The user name of the project administrator who will install the Cloud Pak for Data control plane.\n    project-name :  Give any name where you will install Cloud Pak for Data Control Plane.\n\n6.\tRun the following command to install Control Plane\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly lite --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n\n7.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly lite --namespace <project-name>\n    ```\n8.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Data Virtualization\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly dv --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly dv --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Data Virtualization\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly dv --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly dv --namespace <project-name>\n    ```\n    At the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by loggin in with admin/password\n7.\tLogin to Cloud Pak for Data Web Console. Click the Services icon from the top right corner of the user interface\n8.\tFrom the list of services, locate the Data Virtualization service under the Data sources category. Click the action menu and select Provision instance. \n9.\tCheck the “You must check this box if you updated the kernel semaphore parameter” box\n10.\tSpecify the resources that you want to allocate to the Data Virtualization worker nodes in the Nodes section\n    a.\tSpecify the number of Data Virtualization worker nodes to allocate to the service. Recommended: One worker node is sufficient for most workloads.\n    b.\tSpecify the number of cores to allocate to each worker node. 16 cores is recommended\n    c.\tSpecify the amount of memory to allocate to each worker node. 64 GB is recommended.\n\n    ![IBM Data Virtualization](images/ConfigureDV.png)\n\n11.\tIn Storage Section, Select Persistent Storage class as “ibmc-file-gold-gid”. You can change the amount of storage based on your requirements. Select Cache Storage class as “ibmc-file-gold-gid”. You can change the amount of cache storage based on your requirements.\n\n    ![IBM Data Virtualization](images/ConfigureDV1.png)\n\n12.\tClick Next\n13.\tVerify the summary and click on Provision. It will take 10-15 mins to provision.\n\n### Installing Watson Studio\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wsl --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wsl --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Watson Studio\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly wsl --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly wsl --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Watson Machine Learning\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wml --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wml --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Watson Machine Learning\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly wml --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly wml --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Watson Openscale\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly aiopenscale --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly aiopenscale --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Watson Openscale\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly aiopenscale --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly aiopenscale --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Cognos Dashboards\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly cde --namespace <project-name>\n    ```\n\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly cde --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Cognos Dashboards\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly cde --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly cde --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Watson Knowledge Catalog\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wkc --namespace <project-name>\n    ```\n\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wkc --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Watson Knowledge Catalog\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly wkc --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly wkc --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing DataStage Enterprise\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly ds-ent --namespace <project-name>\n    ```\n\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly ds-ent --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install DataStage Enterprise\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly ds-ent --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly ds-ent --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Regulatory Accelerator\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly iira --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly iira --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Regulatory Accelerator\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly iira --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly iira --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing DB2 Warehouse\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly db2wh --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly db2wh --namespace <project-name> --apply\n    ```\n5.\tIf you want to run database on a dedicated compute nodes, follow the steps at : https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_current/cpd/svc/dbs/db2w-dednodes.html to label nodes\n6.\tRun the following command to install DB2 Warehouse\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly db2wh --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n7.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly db2wh --namespace <project-name>\n    ```\n8.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n9.\tFrom navigation on the left side, select Collect -> My data\n10.\tOpen the Databases tab, which is only visible after you install the database service.\n11.\tClick Create a database.\n12.\tSelect the database type and version. Click Next.\n13.\tIn the Configure area, specify the number of nodes, memory per node, and CPU per node. An error message will be displayed if adequate resources are not found\n14.\tIf you are using a dedicated node, click Deploy database on dedicated nodes and enter the node label in the Value for node label box that you mentioned in Step 5 above\n\n    ![IBM DB2 Warehouse Provisioning](images/ConfigureDB2wh.png)\n\n15.\tFor database storage, you can choose to keep your system data and user data together in a single location or put them in separate locations. System data contains the information that is used by Db2 Warehouse to manage and configure the database. User data is the main database data. If you choose Separate locations for all data, you must specify a storage volume type, a name, and a size for both storage locations.\n16.\tSelect Storage class “ibmc-file-gold-gid” and specify size for the System, User and Backup storage\n\n    ![IBM DB2 Warehouse Provisioning](images/ConfigureDB2wh1.png)\n\n17.\tClick Next\n18.\tEnsure that the summary is correct and click Create.\n19.\tYou might have to wait 5 to 40 minutes, based on the number of worker nodes and amount of memory that were allocated to the deployment.The database is ready when it shows up as Available on the Databases tab.\n\n\n### Installing DB2 Advanced Edition\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly db2oltp --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly db2oltp --namespace <project-name> --apply\n    ```\n5.\tIf you want to run database on a dedicated compute nodes, follow the steps at : https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_current/cpd/svc/dbs/aese-dednodes.html to label nodes\n6.\tRun the following command to install DB2 Advanced Edition\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly db2oltp --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n7.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly db2oltp --namespace <project-name>\n    ```\n8.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n9.\tFrom navigation on the left side, select Collect -> My data\n10.\tOpen the Databases tab, which is only visible after you install the database service.\n11.\tClick Create a database.\n12.\tSelect the database type and version. Click Next.\n13.\tIn the Configure area, specify the number of nodes, memory per node, and CPU per node. An error message will be displayed if adequate resources are not found\n14.\tIf you are using a dedicated node, click Deploy database on dedicated nodes and enter the node label in the Value for node label box that you mentioned in Step 5 above\n\n    ![IBM DB2 Advanced Edition Provisioning](images/ConfigureDB2oltp.png)\n\n15.\tFor database storage, you can choose to keep your system data and user data together in a single location or put them in separate locations. System data contains the information that is used by Db2 to manage and configure the database. User data is the main database data. If you choose Separate locations for all data, you must specify a storage volume type, a name, and a size for both storage locations.\n16.\tSelect Storage class “ibmc-file-gold-gid” and specify size for the System, User and Backup storage\n\n    ![IBM DB2 Advanced Edition Provisioning](images/ConfigureDB2oltp.png)\n\n17.\tClick Next\n18.\tEnsure that the summary is correct and click Create.\n19.\tYou might have to wait 5 to 40 minutes, based on the number of worker nodes and amount of memory that were allocated to the deployment. The database is ready when it shows up as Available on the Databases tab.\n\n### Installing Cognos Analytics\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly ca --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly ca --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Cognos Analytics\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly ca --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly ca --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n8.\tTo configure database for content store for Cognos Analytics\n\n    a.\tYou need to have DB2 Advanced Edition installed prior to provisioning Cognos Analytics instance\n\n    b.\tIn IBM Cloud Pak for Data, click My instances, and open the details for the provisioned IBM Db2 Advanced Edition instance.\n\n    c.\tCollect the following details:\n\n    - Database name\n    - Deployment id\n    - Username\n    - Password\n    - JDBC Connection URL\n\n    ![IBM DB2 Advanced Edition connection details](images/DB2connection.png)\n\n    d.\tRun below command in terminal\n    ```\n    export NAMESPACE=<Namespace of your CPD Installation>\n    export DB2USERNAME=<USERNAME>\n    export DB2PASSWORD=<PASSWORD>\n    export DB2DEPLOYMENTID=<DEPLOYMENTID>\n    export CMD=\"env DB2USERNAME=$DB2USERNAME DB2PASSWORD=$DB2PASSWORD  bash\"\n    oc  exec -ti $DB2DEPLOYMENTID-db2u-0 -n $NAMESPACE -- $CMD\n    ```\n\n    e.\tFrom DB2 container , run below commands\n    ```\n    cd /mnt/blumeta0/home/db2inst1/sqllib\n    . ./db2profile   \n    db2 CONNECT to BLUDB user $DB2USERNAME using  $DB2PASSWORD \n    db2 UPDATE DATABASE CONFIGURATION USING APPLHEAPSZ 1024 DEFERRED; \n    db2 UPDATE DATABASE CONFIGURATION USING LOCKTIMEOUT 240 DEFERRED;\n    db2 CREATE BUFFERPOOL CMDB_08KBP IMMEDIATE SIZE 1000 PAGESIZE 8K;\n    db2 CREATE BUFFERPOOL CMDB_32KBP IMMEDIATE SIZE 1000 PAGESIZE 32K;\n    db2 CREATE SYSTEM TEMPORARY TABLESPACE TSN_SYS_CMDB IN DATABASE PARTITION GROUP IBMTEMPGROUP PAGESIZE 32K BUFFERPOOL CMDB_32KBP;\n    db2 CREATE USER TEMPORARY TABLESPACE TSN_USR_CMDB IN DATABASE PARTITION GROUP IBMDEFAULTGROUP PAGESIZE 8K BUFFERPOOL CMDB_08KBP;\n    db2 CREATE REGULAR TABLESPACE TSN_REG_CMDB IN DATABASE PARTITION GROUP IBMDEFAULTGROUP PAGESIZE 8K BUFFERPOOL CMDB_08KBP; \n    db2 DROP TABLESPACE USERSPACE1;\n    db2 CREATE SCHEMA db2COGNOS AUTHORIZATION $DB2USERNAME;\n    db2 ALTER BUFFERPOOL ibmdefaultbp size 49800\n\n    exit\n    ```\n\n    f.\tCreate a connection to DB2 instance created\n\n    - Log in to the Cloud Pak for Data web client.\n    - From the menu, select Connections.\n    - Click Add connection.\n    - Enter a name and a description for the connection.\n    - Select Db2 for the Connection type.\n    - On the New connection page, enter the following information from step 2 in this task.\n        - Host (Collected from step d above)\n        - Port (Collected from step d above)\n        - Database name\n        - Username\n        - Password\n    - To test the connection, click Test connection on the New connection page.\n    - Click Create. The connection is saved.\n\n    ![IBM DB2 Advanced Edition connection](images/DB2connection1.png)\n\n9.\tProvision an instance of Cognos Analytics\n\n    a.\tLog in to Cloud Pak for Data as an administrator.\n\n    b.\tFrom the toolbar, click the Services icon\n\n    c.\tFind the Cognos Analytics service and ensure that it is Available.\n\n    d.\tFrom the action menu, select Provision instance.\n    \n    e.\tSelect a Shared Volume Storage class ibmc-file-gold-gid.\n\n    ![IBM Cognos Analytics Provisioning](images/createCA.png)\n                \n    f.\tSelect the plan size for the instance.\n\n    g.\tSelect the connection that you previously defined.\n\n    ![IBM Cognos Analytics Provisioning](images/createCA1.png)\n\n    h.\tClick Next.\n\n    i.\tReview the summary and click Create. It will take approximately 30 min to provision an instance\n\n    ![IBM Cognos Analytics Provisioning](images/createCA2.png)\n\n### Installing Watson Assistant\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tCordon all non-bare metal server nodes\n    ```\n    oc adm cordon <node-name>\n    ```\n4.\tCreate a wa-repo.yaml file with below contents. Replace {entitlement-key} with your Entitlement key\n    ```\n    registry:\n        - url: cp.icr.io/cp/cpd\n        username: \"cp\"\n        apikey: {entitlement-key}\n        namespace: \"\"\n        name: base-registry\n        - url: cp.icr.io\n        username: \"cp\"\n        apikey: {entitlement-key}\n        namespace: \"cp/watson-assistant\"\n        name: wa-registry\n    fileservers:\n        - url: https://raw.github.com/IBM/cloud-pak/master/repo/cpd3\n    ```\n5.\tCreate a Portworx storage class named “portworx-assistant”. Run below snippet\n    ```\n    cat <<EOF | oc create -f -\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n        name: portworx-assistant\n    parameters:\n        repl: \"3\"\n        priority_io: \"high\"\n        io_profile: \"db\"\n        block_size: \"64k\"\n    allowVolumeExpansion: true\n    provisioner: kubernetes.io/portworx-volume\n    reclaimPolicy: Retain\n    volumeBindingMode: Immediate\n    EOF\n    ```\n6.\tRun the following command to bind the restricted SecurityContextConstraint to the Cloud Pak for Data namespace in which you will install the service:\n    ```\n    oc adm policy add-scc-to-group restricted system:serviceaccounts:{namespace}\n    ```\n    where {namespace} is the namespace in which Cloud Pak for Data is installed.\n7.\tAdd the cluster namespace label to your service namespace.\n    ```\n\toc label --overwrite namespace {namespace} ns={namespace}\n\toc project {namespace}\n    ```\n    {namespace} – project name where Cloud Pak for data is installed and Watson Assistant is to be installed\n8.\tFrom the namespace where the Cloud Pak for Data cluster is installed, get the name of the secret for pulling images from the internal Docker registry.\n    ```\n    oc get secrets | grep default-dockercfg\n    ```\n    Make a note of the secret. You will add it as the value for the global.image.pullSecret setting in the override file that you create in the next step. For example:\n    ```\n    global:\n        image:\n        pullSecret: \"default-dockercfg-gqfb4\"\n        ```\n9.\tCreate an override file as below where you can change configuration settings of Watson Assistant deployment. Make sure you update pullSecret from the above step. For more information : https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_current/cpd/svc/watson/assistant-override.html\n    ```\n    global:\n        # On uninstall do not preserve the datastores\n        keep: false\n\n        # The storage class used for datastores\n        storageClassName: \"portworx-assistant\"\n\n        # Choose between \"Development\" and \"Production\"\n        deploymentType: \"Development\"\n\n        # The name of the secret for pulling images.\n        # The value for \"global.image.pullSecret\" below does not need to be changed for Development\n        # installations where pods will pull docker images directly from the Entitled Docker Registry.\n        # For Production installations where docker images will be pulled locally to the Openshift\n        # Docker Registry, \"global.image.pullSecret\" will need to be set to the value obtained by\n        # running oc get secrets | grep default-dockercfg in the namespace where IBM Cloud\n        # Pak for Data is installed.\n  \n        image:\n        pullSecret: \"default-dockercfg-l8fgp\"\n\n        # global.languages.[language] - Specifies whether [language] should be installed or not.\n        languages:\n        english: true\n        german:  false\n        arabic: false\n        spanish: false\n        french: false\n        italian: false\n        japanese: false\n        korean: false\n        portuguese: false\n        czech: false\n        dutch: false\n        chineseTraditional: false\n        chineseSimplified: false\n\n    # the storageclass used for postgres backup\n    postgres:\n        backup:\n        dataPVC:\n            storageClassName: portworx-assistant\n\n    # use \"2.5.0.0\" for CP4D 2.5.0 (carbon 9) and \"3.0.0.0\" for CP4D 3.0.0 and 3.0.1 (carbon 10)\n    ingress:\n        wcnAddon:\n        addon:\n            platformVersion: \"3.0.0.0\"\n    ```\n\n10.\tRun the following command to install Watson Assistant\n    ```\n    bin/cpd-Operating_System --repo wa-repo.yaml --assembly ibm-watson-assistant --version 1.4.2 --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass portworx-assistant --override overrides.yaml\n    ```\n11.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly ibm-watson-assistant --namespace <project-name>\n    ```\n12.\tProvision an instance of Watson Assistant\n    a.\tLog in to Cloud Pak for Data as an administrator.\n    b.\tFrom the toolbar, click the Services icon\n    c.\tFind the Watson Assistant service and ensure that it is Available.\n    d.\tFrom the action menu, select Provision instance.\n    e.\tGive Instance name and Click on Create.\n\n13. Uncordon all non-bare metal server nodes\n    ```\n    oc adm cordon <node-name>\n    ```\n\n### Installing Watson Discovery\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tMake sure you did Kernel Parameters settings mentioned in “Setting up Openshift Cluster for Cloud Pak for Data Installation” Step 3\n4.\tCordon all non-bare metal server nodes\n    ```\n    oc adm cordon <node-name>\n    ```\n5.\tCreate a wd-repo.yaml file with below contents. Replace {entitlement-key} with your Entitlement key\n    ```\n    registry:\n        - url: cp.icr.io/cp/cpd\n        username: \"cp\"\n        apikey: {entitlement-key}\n        namespace: \"\"\n        name: base-registry\n        - url: cp.icr.io/cp/watson-discovery\n        username: \"cp\"\n        apikey: {entitlement-key}\n        name: watson-discovery-registry\n    fileservers:\n        - url: https://raw.github.com/IBM/cloud-pak/master/repo/cpd3\n    ```\n6.\tCreate Portworx storage class named “portworx-db-gp3”. Run below snippet\n    ``` \n    cat <<EOF | oc create -f -\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n        name: portworx-db-gp3\n    parameters:\n        io_profile: \"db_remote\"\n        repl: \"3\"\n    allowVolumeExpansion: true\n    provisioner: kubernetes.io/portworx-volume\n    reclaimPolicy: Retain\n    volumeBindingMode: Immediate\n    EOF\n    ```\n7.\tFrom the namespace where the Cloud Pak for Data cluster is installed, get the name of the secret for pulling images from the internal Docker registry.\n    ```\n    oc get secrets | grep default-dockercfg\n    ```\n    Make a note of the secret. You will add it as the value for the global.image.pullSecret setting in the override file that you create in the next step. For example:\n    ```\n    global:\n        image:\n        pullSecret: \"default-dockercfg-gqfb4\"\n    ```\n8.\tCreate an override file wd-override.yaml as below where you can change configuration settings of Watson Discovery deployment. Make sure you update pullSecret from the above step. For more information : https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_current/cpd/svc/watson/discovery-override.html\n    ```\n    global:\n        deploymentType: \"Development\"\n        contentIntelligence:\n        enabled: true\n        image:\n        # minio/postgresql/rabbitmq\n        pullSecret: \"your-default-dockercfg-secret\"\n        # etcd\n        imagePullSecret: \"<pull-secret>\"\n    core:\n        ingestion:\n        mount:\n            storageClassName: \"portworx-db-gp3\"\n    elastic:\n        persistence:\n        storageClassName: \"portworx-db-gp3\"\n    crust:\n        networkPolicy: \n        create: false\n    mantle: \n        networkPolicy:\n        create: false \n    networkPolicy:\n        create: false\n    ```\n\n9.  See what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly watson-discovery --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n10.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly watson-discovery --namespace <project-name> --apply\n    ```\n11.\tRun the following command to install Watson Discovery\n    ```\n    bin/cpd-Operating_System --repo wd-repo.yaml --assembly watson-discovery --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid --override wd-override.yaml\n    ```\n12.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly watson-discovery --namespace <project-name>\n    ```\n13.\tProvision an instance of Watson Discovery\n    a.\tLog in to Cloud Pak for Data as an administrator.\n    b.\tFrom the toolbar, click the Services icon\n    c.\tFind the Watson Discovery service and ensure that it is Available.\n    d.\tFrom the action menu, select Provision instance.\n    e.\tGive Instance name and Click on Create.\n\n14.\tUncordon all non-bare metal server nodes\n    ```\n    oc adm uncordon <node-name>\n    ```\n\n### Installing Watson Knowledge Studio\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tCreate a wks-repo.yaml file with below contents. Replace {entitlement-key} with your Entitlement key\n    ```\n    registry:\n        - url: cp.icr.io/cp/cpd\n        username: \"cp\"\n        apikey: {entitlement-key}\n        namespace: \"\"\n        name: base-registry\n        - url: cp.icr.io/cp/knowledge-studio\n        username: \"cp\"\n        apikey: {entitlement-key}\n        name: wks-registry\n    fileservers:\n        - url: https://raw.github.com/IBM/cloud-pak/master/repo/cpd3\n    ```\n\n4.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo wks-repo.yaml --assembly watson-ks --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n5.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo wks-repo.yaml --assembly watson-ks --namespace <project-name> --apply\n    ```\n6.\tRun the following command to install Watson Knowledge Studio\n    ```\n    bin/cpd-Operating_System --repo wks-repo.yaml --assembly watson-ks --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n7.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly watson-ks --namespace <project-name>\n    ```\n8.\tProvision an instance of Watson Knowledge Studio\n\n    a.\tLog in to Cloud Pak for Data as an administrator.\n\n    b.\tFrom the toolbar, click the Services icon\n\n    c.\tFind the Watson Knowledge Studio service and ensure that it is Available.\n\n    d.\tFrom the action menu, select Provision instance.\n\n    e.\tGive Instance name and Click on Create.\n","type":"Mdx","contentDigest":"6bdcbc03954ddfce6265b49aeab509a4","counter":811,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Cloud Pak for Data 3.0.1 on IBM Managed Openshift 4.3"},"exports":{},"rawBody":"---\ntitle: Cloud Pak for Data 3.0.1 on IBM Managed Openshift 4.3\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\n</PageDescription>\n\n## Install Cloud Pak for Data 3.0.1 on IBM Managed Openshift 4.3\n\n<AnchorLinks>\n  <AnchorLink>Sizing Openshift Cluster for Cloud Pak for Data 3.0.1</AnchorLink>\n  <AnchorLink>Provision Openshift 4.3 Cluster on IBM Cloud</AnchorLink>\n  <AnchorLink>Setting up Openshift Cluster for Cloud Pak for Data Installation</AnchorLink>\n  <AnchorLink>Setting Portworx Storage</AnchorLink>\n  <AnchorLink>Download Installation files</AnchorLink>\n  <AnchorLink>Installing Control Plane</AnchorLink>\n  <AnchorLink>Installing Data Virtualization</AnchorLink>\n  <AnchorLink>Installing Watson Studio</AnchorLink>\n  <AnchorLink>Installing Watson Machine Learning</AnchorLink>\n  <AnchorLink>Installing Watson Openscale</AnchorLink>\n  <AnchorLink>Installing Cognos Dashboards</AnchorLink>\n  <AnchorLink>Installing Watson Knowledge Catalog</AnchorLink>\n  <AnchorLink>Installing DataStage Enterprise</AnchorLink>\n  <AnchorLink>Installing Regulatory Accelerator</AnchorLink>\n  <AnchorLink>Installing DB2 Warehouse</AnchorLink>\n  <AnchorLink>Installing DB2 Advanced Edition</AnchorLink>\n  <AnchorLink>Installing Cognos Analytics</AnchorLink>\n  <AnchorLink>Installing Watson Assistant</AnchorLink>\n  <AnchorLink>Installing Watson Discovery</AnchorLink>\n  <AnchorLink>Installing Watson Knowledge Studio</AnchorLink>\n</AnchorLinks>\n\n### Sizing Openshift Cluster for Cloud Pak for Data 3.0.1\n\nSizing Worker Nodes based on Services that are to be installed. Refer : https://salesconfig.ibmcloudpack.com/sales/#/zen/configure\nTo do the sizing\n\nPlease note that if you want to install Watson AI services (Watson Assistant, Watson Discovery, Watson AIOps, Watson Language Translator, Watson Speech to Text, Watson Text to Speech) size them separately as they will need bare metal worker nodes and will not work on virtual server worker nodes.\n\n### Provision Openshift 4.3 Cluster on IBM Cloud\n\n**Note:** Make sure you have Administrator and Manager lever permission on the account where you are provisioning the cluster.\n\nProvision Openshift 4.3 Cluster from IBM Cloud console. Select Virtual Server Worker nodes based on the above sizing calculations. If you are installing Watson AI services, we will add Bare metal worker nodes post the cluster creation.\n\n![IBM Openshift Cluster Provision](images/ProvisionCluster.png)\n\nOnce the cluster is created, create a new worker pool which will have bare metal servers required for Watson AI Services installation.\n\n![IBM Openshift Cluster Config](images/ClusterConfig.png)\n\nOnce the cluster is ready, launch its console and on the right top corner, from copy login command, get the token to login to Openshift cluster remotely using cli\n \n![IBM Openshift Cluster Config](images/CopyToken.png)\n\nMake sure you have a system with Openshift and IBM Cloud cli installed.\nhttps://cloud.ibm.com/docs/openshift?topic=openshift-openshift-cli#cli_oc\nhttps://cloud.ibm.com/docs/cli/reference/bluemix_cli/download_cli.html\n\nExecute oc login command obtained in above step from Openshift Web Console\n\n### Setting up Openshift Cluster for Cloud Pak for Data Installation\n\n1.\tCreate an external route of Openshift Image registry.\n    Use token obtained in abive step to login from a system to OpenShift Cluster and run below commands to create an external route\n\n    ```\n    oc create route reencrypt --service=image-registry -n openshift-image-registry\n    oc annotate route image-registry --overwrite haproxy.router.openshift.io/balance=source -n openshift-image-registry\n    ```\n\n2.\tResize image registry storage volume\n    Default size of Openshift image registry will not be sufficient to load images if you are going to install multiple Services on Cloud Pak for Data. Hence it needs to be resized to 200GB. Run below commands to do it.\n\n    ```\n    ibmcloud login\n    ```\n    (login into Account where your Openshift Cluster is setup)\n    ```\n    registry_pv=`oc get pvc -n openshift-image-registry | grep \"image-registry-storage\" | awk '{print $3}'`\n    volid=`oc describe pv $registry_pv -n openshift-image-registry | grep volumeId`\n    IFS='='\n    read -ra vol <<< \"$volid\"\n    volume=${vol[1]}\n    echo volume id is $volume\n    ibmcloud sl file volume-modify $volume --new-size 200 --new-tier 10 –force\n    ```\n\n3.\tSet kernel parameters (https://www.ibm.com/support/knowledgecenter/SSQNUZ_3.0.1/cpd/install/node-settings.html)\n    Since we do not have ssh access to worker nodes on ROKS, we will use daemonset to perform kernel parameter settings. Create setkernelparameters.yaml file with below contents\n\n    ```apiVersion: tuned.openshift.io/v1\n    kind: Tuned\n    metadata:\n      name: cp4d-wkc-ipc\n      namespace: openshift-cluster-node-tuning-operator\n    spec:\n      profile:\n      - name: cp4d-wkc-ipc\n        data: |\n          [main]\n          summary=Tune IPC Kernel parameters on OpenShift Worker Nodes running WKC Pods\n          [sysctl]\n          kernel.shmall = 33554432\n          kernel.shmmax = 68719476736\n          kernel.shmmni = 16384\n          kernel.sem = 250 1024000 100 16384\n          kernel.msgmax = 65536\n          kernel.msgmnb = 65536\n          kernel.msgmni = 32768\n          vm.max_map_count = 262144\n      recommend:\n      - match:\n        - label: node-role.kubernetes.io/worker\n        priority: 10\n        profile: cp4d-wkc-ipc\n    ```\n\n    Run below commands to do the changes\n\n    ```\n    oc project kube-system\n    oc create -f setkernelparameters.yaml\n    ```\n\n4.\tChange NFS mount settings\n    If you are using IBM Cloud File Storage for PVC creation, we need to make sure pvcs are mounted with root permissions. \n\n    a.\tCreate a service account called norootsquash by running the following command:\n\n    ```\n    oc create -f - << EOF\n    apiVersion: v1\n    kind: ServiceAccount\n    metadata:\n      name: norootsquash\n      namespace: kube-system\n    EOF\n    ```\n\n    b.\tGive the service account privileged security context constraints (SCC) by running the following command:\n\n    ``` \n    oc adm policy add-scc-to-user privileged system:serviceaccount:kube-system:norootsquash\n    ```\n\n    c.\tCreate the daemonset by running the following command:\n\n    ```\n    oc create -f - << EOF\n    apiVersion: apps/v1\n    kind: DaemonSet\n    metadata:\n      name: norootsquash\n      namespace: kube-system\n      labels:\n        tier: management\n        app: norootsquash\n    spec:\n      selector:\n        matchLabels:\n          name: norootsquash\n      template:\n        metadata:\n          labels:\n            name: norootsquash\n        spec:\n          serviceAccountName: norootsquash\n          initContainers:\n            - resources:\n                requests:\n                  cpu: 0.1\n              securityContext:\n                privileged: true\n              image: alpine:3.6\n              name: unrootsquash\n              command: [\"chroot\", \"/host\", \"sh\", \"-c\"]\n              args:\n                - >\n                  grep \"^Domain = slnfsv4.com\" /etc/idmapd.conf;\n                  if [ \"\\$?\" -ne \"0\" ] ; then\n                    sed -i 's/.*Domain =.*/Domain = slnfsv4.com/g' /etc/idmapd.conf;\n                    nfsidmap -c;\n                    rpc.idmapd\n                  fi;\n              volumeMounts:\n                - name: host\n                  mountPath: /host\n          containers:\n            - resources:\n                requests:\n                  cpu: 0.1\n              image: alpine:3.6\n              name: sleep\n              command: [\"/bin/sh\", \"-c\"]\n              args:\n                - >\n                  while true; do\n                    sleep 100000;\n                  done\n          volumes:\n            - hostPath:\n                path: /\n                type: Directory\n              name: host\n    EOF\n    ```\n\n### Setting Portworx Storage\n\nWatson AI services (Watson Assistant, Watson Discovery, Watson Knowledge Studio, Watson Speech to Text and Watson text to Speech) install is currently supported only with Enterprise Portworx storage. Follow the steps mentioned below to set that up for ROKS. Make sure you are logged in to IBM Cloud and Openshift using CLI (ibmcloud and oc)\n1.\tAttach Block Storage to worker nodes (https://cloud.ibm.com/docs/containers?topic=containers-utilities#block_storage_attacher)\n\n    a.\tInstall helm on your local system from where you are running the commands. (https://github.com/helm/helm/releases)\n\n    b.\tRun below command\n    ```\n    oc project kube-system\n    ```\n    c.  Below command should return 0 results\n    ```\n    oc get serviceaccount -n kube-system | grep tiller\n    ```\n    d.  Run below commands\n    ```\n    oc create serviceaccount tiller -n kube-system\n    oc create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller -n kube-system\n    oc get serviceaccount -n kube-system tiller\n    helm init --service-account tiller\n    oc get pods -n kube-system -l app=helm\n    helm repo add iks-charts https://icr.io/helm/iks-charts\n    helm repo add ibm-charts https://raw.githubusercontent.com/IBM/charts/master/repo/stable\n    helm repo add ibm-community https://raw.githubusercontent.com/IBM/charts/master/repo/community\n    helm repo add entitled https://raw.githubusercontent.com/IBM/charts/master/repo/entitled\n    helm repo update\n    helm install iks-charts/ibm-block-storage-attacher --name block-attacher\n    oc get pod -n kube-system -o wide | grep attacher\n    oc get storageclasses | grep attacher\n    mkdir cp4d\n    cd cp4d\n    git clone https://github.com/IBM/ibmcloud-storage-utilities.git\n    cd ibmcloud-storage-utilities/block-storage-provisioner\n    ```\n    e.\tvi yamlgen.yaml (provide the storage as you would need for your application, clustername and size of the block storage. Min 500 GB is required for Watson Assistant)\n        Provide the storage details i.e your Openshift Cluster name and region where it is located.\n\n    ![IBM Block Storage Provisioning](images/yamlgen.png)\n\n    f.\tCreate Classic Infrastructure Key\n\n    - On IBM Cloud Console, from menu bar select Manage -> Access\n    - Select API keys tab and from drop down select Classic Infrastructure API keys.\n    - If one is already listed, click Actions menu (3 dots) > Details\n    - Copy API username and API key\n\n    ![IBM Cloud API keys](images/CopyAPIKeys.png) \n\n    g.\texport SL_USERNAME=infrastructure username obtained in above step\n\n    h.\texport SL_API_KEY=infrastructure API key obtained in above step\n\n    i.\tEdit Dockerfile and update first line to “FROM ubuntu:18.04”\n\n    j.\tEdit px_iks_utils.py (only if you have virtual server nodes as well as bare metal nodes, this is to avoid attaching block storage on virtual server nodes). Add below line on line number 83  : ``` if re.search('m[a-z]3c', w['machineType']): ``` It should like this \n\n    ![IBM Block Storage Provisioning](images/px_iks_utils.png) Add “import re” on the top below existing import statements.\n\n    k.\tRun below commands and check for annotation ibm.io/attachstatus: attached\n    ```\n    docker build -t mkpvyaml .\n    docker run --rm -v `pwd`:/data -v ~/.bluemix:/config -e SL_API_KEY=$SL_API_KEY -e SL_USERNAME=$SL_USERNAME mkpvyaml\n    oc apply -f pv-<cluster-name>.yaml\n    oc describe pv <pvname created in above step>\n    ```\n        \n    l.\tCordon nodes which are not bare metal server with below command. Execute below command for each non bare metal node.\n    ```\n    oc adm cordon <node-name>\n    ```\n    ![IBM Block Storage Provisioning](images/CornonNodes.png)\n\n2.\tTo use internal portworx key-value database instead of etcd service, copy the imagepull secret from default to kube-system namespace.\n    ```\n    oc get secrets -n default | grep icr\n    oc get secret -n default all-icr-io -o yaml | sed 's/default/kube-system/g' | oc -n kube-system create -f -\n    oc patch -n kube-system serviceaccount/default --type='json' -p='[{\"op\":\"add\",\"path\":\"/imagePullSecrets/-\",\"value\":{\"name”:”all-icr-io\"}}]'\n    ```\n\n3.\tFrom IBM Cloud Catalog, provision “Portworx Enterprise” service. Select same region as your Openshift Cluster. Select Enterprise plan from Pricing Plan. In IBM Cloud API Key, mention same key which was used to create block storage in above steps.  Select “Portworx KVDB” from Portworx metadata key-value store dropdown.\n\n    ![IBM Portworx Service](images/PortworxService.png)\n\n4.\tCheck if portworx pods are created and up successfully.\n    ```\n    oc get pods -n kube-system | grep 'portworx\\|stork'\n    ```\n\n5.\tLogin to one of the portworx pods and list the status of your Portworx cluster\n    ```\n    PX_POD=$(oc get pods -l name=portworx -n kube-system -o jsonpath='{.items[0].metadata.name}')\n    oc exec $PX_POD -n kube-system -- /opt/pwx/bin/pxctl status\n    ```\n\n    Non-bare metal server worker nodes will be listed with No StorageNode.\n\n    ![IBM Portworx Service](images/PortworxPods.png)\n\n### Download Installation files\n\n1.\tDownload installation files from: https://github.com/IBM/cpd-cli/releases\n2.\tCopy the downloaded tar file to a system where you have setup oc cli\n3.\tExtract the contents of the tar file\n4.\tObtain your Entitlement key from : https://myibm.ibm.com/products-services/containerlibrary by logging in with you IBM ID connected with Partner World\n5.\tEdit  repo.yaml which can be found in the extracted contents of the tar file. Specify username as cp and apiKey as Entitlement Key obtained in above step.\n\n**Note :** If you are installing multiple services on your cluster, you must run the installations one at a time and wait until the installation completes before installing another service. You cannot run the installations in parallel.\n\n### Installing Control Plane\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly lite --namespace <project-name>\n    ```\n\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give any name where you will install Cloud Pak for Data Control Plane. For example:  cpd301. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly lite --namespace <project-name> --apply\n    ```\n5.\tRun the following command to grant cpd-admin-role to the project administration user:\n    ```\n    oc adm policy add-role-to-user cpd-admin-role <project_admin> --role-namespace=<project-name> -n <project-name>\n    ```\n\n    project-admin : The user name of the project administrator who will install the Cloud Pak for Data control plane.\n    project-name :  Give any name where you will install Cloud Pak for Data Control Plane.\n\n6.\tRun the following command to install Control Plane\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly lite --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n\n7.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly lite --namespace <project-name>\n    ```\n8.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Data Virtualization\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly dv --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly dv --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Data Virtualization\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly dv --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly dv --namespace <project-name>\n    ```\n    At the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by loggin in with admin/password\n7.\tLogin to Cloud Pak for Data Web Console. Click the Services icon from the top right corner of the user interface\n8.\tFrom the list of services, locate the Data Virtualization service under the Data sources category. Click the action menu and select Provision instance. \n9.\tCheck the “You must check this box if you updated the kernel semaphore parameter” box\n10.\tSpecify the resources that you want to allocate to the Data Virtualization worker nodes in the Nodes section\n    a.\tSpecify the number of Data Virtualization worker nodes to allocate to the service. Recommended: One worker node is sufficient for most workloads.\n    b.\tSpecify the number of cores to allocate to each worker node. 16 cores is recommended\n    c.\tSpecify the amount of memory to allocate to each worker node. 64 GB is recommended.\n\n    ![IBM Data Virtualization](images/ConfigureDV.png)\n\n11.\tIn Storage Section, Select Persistent Storage class as “ibmc-file-gold-gid”. You can change the amount of storage based on your requirements. Select Cache Storage class as “ibmc-file-gold-gid”. You can change the amount of cache storage based on your requirements.\n\n    ![IBM Data Virtualization](images/ConfigureDV1.png)\n\n12.\tClick Next\n13.\tVerify the summary and click on Provision. It will take 10-15 mins to provision.\n\n### Installing Watson Studio\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wsl --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wsl --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Watson Studio\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly wsl --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly wsl --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Watson Machine Learning\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wml --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wml --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Watson Machine Learning\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly wml --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly wml --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Watson Openscale\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly aiopenscale --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly aiopenscale --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Watson Openscale\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly aiopenscale --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly aiopenscale --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Cognos Dashboards\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly cde --namespace <project-name>\n    ```\n\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly cde --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Cognos Dashboards\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly cde --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly cde --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Watson Knowledge Catalog\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wkc --namespace <project-name>\n    ```\n\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly wkc --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Watson Knowledge Catalog\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly wkc --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly wkc --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing DataStage Enterprise\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly ds-ent --namespace <project-name>\n    ```\n\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly ds-ent --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install DataStage Enterprise\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly ds-ent --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly ds-ent --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing Regulatory Accelerator\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly iira --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly iira --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Regulatory Accelerator\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly iira --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly iira --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n\n### Installing DB2 Warehouse\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly db2wh --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly db2wh --namespace <project-name> --apply\n    ```\n5.\tIf you want to run database on a dedicated compute nodes, follow the steps at : https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_current/cpd/svc/dbs/db2w-dednodes.html to label nodes\n6.\tRun the following command to install DB2 Warehouse\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly db2wh --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n7.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly db2wh --namespace <project-name>\n    ```\n8.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n9.\tFrom navigation on the left side, select Collect -> My data\n10.\tOpen the Databases tab, which is only visible after you install the database service.\n11.\tClick Create a database.\n12.\tSelect the database type and version. Click Next.\n13.\tIn the Configure area, specify the number of nodes, memory per node, and CPU per node. An error message will be displayed if adequate resources are not found\n14.\tIf you are using a dedicated node, click Deploy database on dedicated nodes and enter the node label in the Value for node label box that you mentioned in Step 5 above\n\n    ![IBM DB2 Warehouse Provisioning](images/ConfigureDB2wh.png)\n\n15.\tFor database storage, you can choose to keep your system data and user data together in a single location or put them in separate locations. System data contains the information that is used by Db2 Warehouse to manage and configure the database. User data is the main database data. If you choose Separate locations for all data, you must specify a storage volume type, a name, and a size for both storage locations.\n16.\tSelect Storage class “ibmc-file-gold-gid” and specify size for the System, User and Backup storage\n\n    ![IBM DB2 Warehouse Provisioning](images/ConfigureDB2wh1.png)\n\n17.\tClick Next\n18.\tEnsure that the summary is correct and click Create.\n19.\tYou might have to wait 5 to 40 minutes, based on the number of worker nodes and amount of memory that were allocated to the deployment.The database is ready when it shows up as Available on the Databases tab.\n\n\n### Installing DB2 Advanced Edition\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly db2oltp --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly db2oltp --namespace <project-name> --apply\n    ```\n5.\tIf you want to run database on a dedicated compute nodes, follow the steps at : https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_current/cpd/svc/dbs/aese-dednodes.html to label nodes\n6.\tRun the following command to install DB2 Advanced Edition\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly db2oltp --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n7.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly db2oltp --namespace <project-name>\n    ```\n8.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n9.\tFrom navigation on the left side, select Collect -> My data\n10.\tOpen the Databases tab, which is only visible after you install the database service.\n11.\tClick Create a database.\n12.\tSelect the database type and version. Click Next.\n13.\tIn the Configure area, specify the number of nodes, memory per node, and CPU per node. An error message will be displayed if adequate resources are not found\n14.\tIf you are using a dedicated node, click Deploy database on dedicated nodes and enter the node label in the Value for node label box that you mentioned in Step 5 above\n\n    ![IBM DB2 Advanced Edition Provisioning](images/ConfigureDB2oltp.png)\n\n15.\tFor database storage, you can choose to keep your system data and user data together in a single location or put them in separate locations. System data contains the information that is used by Db2 to manage and configure the database. User data is the main database data. If you choose Separate locations for all data, you must specify a storage volume type, a name, and a size for both storage locations.\n16.\tSelect Storage class “ibmc-file-gold-gid” and specify size for the System, User and Backup storage\n\n    ![IBM DB2 Advanced Edition Provisioning](images/ConfigureDB2oltp.png)\n\n17.\tClick Next\n18.\tEnsure that the summary is correct and click Create.\n19.\tYou might have to wait 5 to 40 minutes, based on the number of worker nodes and amount of memory that were allocated to the deployment. The database is ready when it shows up as Available on the Databases tab.\n\n### Installing Cognos Analytics\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly ca --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n4.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly ca --namespace <project-name> --apply\n    ```\n5.\tRun the following command to install Cognos Analytics\n    ```\n    bin/cpd-Operating_System --repo repo.yaml --assembly ca --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n6.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly ca --namespace <project-name>\n    ```\n7.\tAt the end of the installation, an URL will be printed which is a Cloud Pak for Data web console URL. You can verify it by logging in with admin/password\n8.\tTo configure database for content store for Cognos Analytics\n\n    a.\tYou need to have DB2 Advanced Edition installed prior to provisioning Cognos Analytics instance\n\n    b.\tIn IBM Cloud Pak for Data, click My instances, and open the details for the provisioned IBM Db2 Advanced Edition instance.\n\n    c.\tCollect the following details:\n\n    - Database name\n    - Deployment id\n    - Username\n    - Password\n    - JDBC Connection URL\n\n    ![IBM DB2 Advanced Edition connection details](images/DB2connection.png)\n\n    d.\tRun below command in terminal\n    ```\n    export NAMESPACE=<Namespace of your CPD Installation>\n    export DB2USERNAME=<USERNAME>\n    export DB2PASSWORD=<PASSWORD>\n    export DB2DEPLOYMENTID=<DEPLOYMENTID>\n    export CMD=\"env DB2USERNAME=$DB2USERNAME DB2PASSWORD=$DB2PASSWORD  bash\"\n    oc  exec -ti $DB2DEPLOYMENTID-db2u-0 -n $NAMESPACE -- $CMD\n    ```\n\n    e.\tFrom DB2 container , run below commands\n    ```\n    cd /mnt/blumeta0/home/db2inst1/sqllib\n    . ./db2profile   \n    db2 CONNECT to BLUDB user $DB2USERNAME using  $DB2PASSWORD \n    db2 UPDATE DATABASE CONFIGURATION USING APPLHEAPSZ 1024 DEFERRED; \n    db2 UPDATE DATABASE CONFIGURATION USING LOCKTIMEOUT 240 DEFERRED;\n    db2 CREATE BUFFERPOOL CMDB_08KBP IMMEDIATE SIZE 1000 PAGESIZE 8K;\n    db2 CREATE BUFFERPOOL CMDB_32KBP IMMEDIATE SIZE 1000 PAGESIZE 32K;\n    db2 CREATE SYSTEM TEMPORARY TABLESPACE TSN_SYS_CMDB IN DATABASE PARTITION GROUP IBMTEMPGROUP PAGESIZE 32K BUFFERPOOL CMDB_32KBP;\n    db2 CREATE USER TEMPORARY TABLESPACE TSN_USR_CMDB IN DATABASE PARTITION GROUP IBMDEFAULTGROUP PAGESIZE 8K BUFFERPOOL CMDB_08KBP;\n    db2 CREATE REGULAR TABLESPACE TSN_REG_CMDB IN DATABASE PARTITION GROUP IBMDEFAULTGROUP PAGESIZE 8K BUFFERPOOL CMDB_08KBP; \n    db2 DROP TABLESPACE USERSPACE1;\n    db2 CREATE SCHEMA db2COGNOS AUTHORIZATION $DB2USERNAME;\n    db2 ALTER BUFFERPOOL ibmdefaultbp size 49800\n\n    exit\n    ```\n\n    f.\tCreate a connection to DB2 instance created\n\n    - Log in to the Cloud Pak for Data web client.\n    - From the menu, select Connections.\n    - Click Add connection.\n    - Enter a name and a description for the connection.\n    - Select Db2 for the Connection type.\n    - On the New connection page, enter the following information from step 2 in this task.\n        - Host (Collected from step d above)\n        - Port (Collected from step d above)\n        - Database name\n        - Username\n        - Password\n    - To test the connection, click Test connection on the New connection page.\n    - Click Create. The connection is saved.\n\n    ![IBM DB2 Advanced Edition connection](images/DB2connection1.png)\n\n9.\tProvision an instance of Cognos Analytics\n\n    a.\tLog in to Cloud Pak for Data as an administrator.\n\n    b.\tFrom the toolbar, click the Services icon\n\n    c.\tFind the Cognos Analytics service and ensure that it is Available.\n\n    d.\tFrom the action menu, select Provision instance.\n    \n    e.\tSelect a Shared Volume Storage class ibmc-file-gold-gid.\n\n    ![IBM Cognos Analytics Provisioning](images/createCA.png)\n                \n    f.\tSelect the plan size for the instance.\n\n    g.\tSelect the connection that you previously defined.\n\n    ![IBM Cognos Analytics Provisioning](images/createCA1.png)\n\n    h.\tClick Next.\n\n    i.\tReview the summary and click Create. It will take approximately 30 min to provision an instance\n\n    ![IBM Cognos Analytics Provisioning](images/createCA2.png)\n\n### Installing Watson Assistant\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tCordon all non-bare metal server nodes\n    ```\n    oc adm cordon <node-name>\n    ```\n4.\tCreate a wa-repo.yaml file with below contents. Replace {entitlement-key} with your Entitlement key\n    ```\n    registry:\n        - url: cp.icr.io/cp/cpd\n        username: \"cp\"\n        apikey: {entitlement-key}\n        namespace: \"\"\n        name: base-registry\n        - url: cp.icr.io\n        username: \"cp\"\n        apikey: {entitlement-key}\n        namespace: \"cp/watson-assistant\"\n        name: wa-registry\n    fileservers:\n        - url: https://raw.github.com/IBM/cloud-pak/master/repo/cpd3\n    ```\n5.\tCreate a Portworx storage class named “portworx-assistant”. Run below snippet\n    ```\n    cat <<EOF | oc create -f -\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n        name: portworx-assistant\n    parameters:\n        repl: \"3\"\n        priority_io: \"high\"\n        io_profile: \"db\"\n        block_size: \"64k\"\n    allowVolumeExpansion: true\n    provisioner: kubernetes.io/portworx-volume\n    reclaimPolicy: Retain\n    volumeBindingMode: Immediate\n    EOF\n    ```\n6.\tRun the following command to bind the restricted SecurityContextConstraint to the Cloud Pak for Data namespace in which you will install the service:\n    ```\n    oc adm policy add-scc-to-group restricted system:serviceaccounts:{namespace}\n    ```\n    where {namespace} is the namespace in which Cloud Pak for Data is installed.\n7.\tAdd the cluster namespace label to your service namespace.\n    ```\n\toc label --overwrite namespace {namespace} ns={namespace}\n\toc project {namespace}\n    ```\n    {namespace} – project name where Cloud Pak for data is installed and Watson Assistant is to be installed\n8.\tFrom the namespace where the Cloud Pak for Data cluster is installed, get the name of the secret for pulling images from the internal Docker registry.\n    ```\n    oc get secrets | grep default-dockercfg\n    ```\n    Make a note of the secret. You will add it as the value for the global.image.pullSecret setting in the override file that you create in the next step. For example:\n    ```\n    global:\n        image:\n        pullSecret: \"default-dockercfg-gqfb4\"\n        ```\n9.\tCreate an override file as below where you can change configuration settings of Watson Assistant deployment. Make sure you update pullSecret from the above step. For more information : https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_current/cpd/svc/watson/assistant-override.html\n    ```\n    global:\n        # On uninstall do not preserve the datastores\n        keep: false\n\n        # The storage class used for datastores\n        storageClassName: \"portworx-assistant\"\n\n        # Choose between \"Development\" and \"Production\"\n        deploymentType: \"Development\"\n\n        # The name of the secret for pulling images.\n        # The value for \"global.image.pullSecret\" below does not need to be changed for Development\n        # installations where pods will pull docker images directly from the Entitled Docker Registry.\n        # For Production installations where docker images will be pulled locally to the Openshift\n        # Docker Registry, \"global.image.pullSecret\" will need to be set to the value obtained by\n        # running oc get secrets | grep default-dockercfg in the namespace where IBM Cloud\n        # Pak for Data is installed.\n  \n        image:\n        pullSecret: \"default-dockercfg-l8fgp\"\n\n        # global.languages.[language] - Specifies whether [language] should be installed or not.\n        languages:\n        english: true\n        german:  false\n        arabic: false\n        spanish: false\n        french: false\n        italian: false\n        japanese: false\n        korean: false\n        portuguese: false\n        czech: false\n        dutch: false\n        chineseTraditional: false\n        chineseSimplified: false\n\n    # the storageclass used for postgres backup\n    postgres:\n        backup:\n        dataPVC:\n            storageClassName: portworx-assistant\n\n    # use \"2.5.0.0\" for CP4D 2.5.0 (carbon 9) and \"3.0.0.0\" for CP4D 3.0.0 and 3.0.1 (carbon 10)\n    ingress:\n        wcnAddon:\n        addon:\n            platformVersion: \"3.0.0.0\"\n    ```\n\n10.\tRun the following command to install Watson Assistant\n    ```\n    bin/cpd-Operating_System --repo wa-repo.yaml --assembly ibm-watson-assistant --version 1.4.2 --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass portworx-assistant --override overrides.yaml\n    ```\n11.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly ibm-watson-assistant --namespace <project-name>\n    ```\n12.\tProvision an instance of Watson Assistant\n    a.\tLog in to Cloud Pak for Data as an administrator.\n    b.\tFrom the toolbar, click the Services icon\n    c.\tFind the Watson Assistant service and ensure that it is Available.\n    d.\tFrom the action menu, select Provision instance.\n    e.\tGive Instance name and Click on Create.\n\n13. Uncordon all non-bare metal server nodes\n    ```\n    oc adm cordon <node-name>\n    ```\n\n### Installing Watson Discovery\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tMake sure you did Kernel Parameters settings mentioned in “Setting up Openshift Cluster for Cloud Pak for Data Installation” Step 3\n4.\tCordon all non-bare metal server nodes\n    ```\n    oc adm cordon <node-name>\n    ```\n5.\tCreate a wd-repo.yaml file with below contents. Replace {entitlement-key} with your Entitlement key\n    ```\n    registry:\n        - url: cp.icr.io/cp/cpd\n        username: \"cp\"\n        apikey: {entitlement-key}\n        namespace: \"\"\n        name: base-registry\n        - url: cp.icr.io/cp/watson-discovery\n        username: \"cp\"\n        apikey: {entitlement-key}\n        name: watson-discovery-registry\n    fileservers:\n        - url: https://raw.github.com/IBM/cloud-pak/master/repo/cpd3\n    ```\n6.\tCreate Portworx storage class named “portworx-db-gp3”. Run below snippet\n    ``` \n    cat <<EOF | oc create -f -\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n        name: portworx-db-gp3\n    parameters:\n        io_profile: \"db_remote\"\n        repl: \"3\"\n    allowVolumeExpansion: true\n    provisioner: kubernetes.io/portworx-volume\n    reclaimPolicy: Retain\n    volumeBindingMode: Immediate\n    EOF\n    ```\n7.\tFrom the namespace where the Cloud Pak for Data cluster is installed, get the name of the secret for pulling images from the internal Docker registry.\n    ```\n    oc get secrets | grep default-dockercfg\n    ```\n    Make a note of the secret. You will add it as the value for the global.image.pullSecret setting in the override file that you create in the next step. For example:\n    ```\n    global:\n        image:\n        pullSecret: \"default-dockercfg-gqfb4\"\n    ```\n8.\tCreate an override file wd-override.yaml as below where you can change configuration settings of Watson Discovery deployment. Make sure you update pullSecret from the above step. For more information : https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_current/cpd/svc/watson/discovery-override.html\n    ```\n    global:\n        deploymentType: \"Development\"\n        contentIntelligence:\n        enabled: true\n        image:\n        # minio/postgresql/rabbitmq\n        pullSecret: \"your-default-dockercfg-secret\"\n        # etcd\n        imagePullSecret: \"<pull-secret>\"\n    core:\n        ingestion:\n        mount:\n            storageClassName: \"portworx-db-gp3\"\n    elastic:\n        persistence:\n        storageClassName: \"portworx-db-gp3\"\n    crust:\n        networkPolicy: \n        create: false\n    mantle: \n        networkPolicy:\n        create: false \n    networkPolicy:\n        create: false\n    ```\n\n9.  See what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly watson-discovery --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n10.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo repo.yaml --assembly watson-discovery --namespace <project-name> --apply\n    ```\n11.\tRun the following command to install Watson Discovery\n    ```\n    bin/cpd-Operating_System --repo wd-repo.yaml --assembly watson-discovery --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid --override wd-override.yaml\n    ```\n12.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly watson-discovery --namespace <project-name>\n    ```\n13.\tProvision an instance of Watson Discovery\n    a.\tLog in to Cloud Pak for Data as an administrator.\n    b.\tFrom the toolbar, click the Services icon\n    c.\tFind the Watson Discovery service and ensure that it is Available.\n    d.\tFrom the action menu, select Provision instance.\n    e.\tGive Instance name and Click on Create.\n\n14.\tUncordon all non-bare metal server nodes\n    ```\n    oc adm uncordon <node-name>\n    ```\n\n### Installing Watson Knowledge Studio\n\n1.\tLogin to your Redhat Openshift Cluster\n    ```\n    oc login –token=<obtained from Openshift Web Console> --server=<obtained from Openshift Web Console>\n    ```\n2.\tMake sure you are in a directory where Installation tar is extracted\n3.\tCreate a wks-repo.yaml file with below contents. Replace {entitlement-key} with your Entitlement key\n    ```\n    registry:\n        - url: cp.icr.io/cp/cpd\n        username: \"cp\"\n        apikey: {entitlement-key}\n        namespace: \"\"\n        name: base-registry\n        - url: cp.icr.io/cp/knowledge-studio\n        username: \"cp\"\n        apikey: {entitlement-key}\n        name: wks-registry\n    fileservers:\n        - url: https://raw.github.com/IBM/cloud-pak/master/repo/cpd3\n    ```\n\n4.\tSee what changes need to be made to the cluster, by running the appropriate cpd adm command for your environment:\n    ```\n    bin/cpd-Operating_System adm --repo wks-repo.yaml --assembly watson-ks --namespace <project-name>\n    ```\n    Operating_System :  Matching OS with the system from which you are running commands. For Linux, specify linux. For Mac OS, specify darwin.\n    project-name :  Give project name where you have installed Cloud Pak for Data Control Plane. Use the same name in all next commands.\n\n5.\tApply changes to your cluster which you saw in above step\n    ```\n    bin/cpd-Operating_System adm --repo wks-repo.yaml --assembly watson-ks --namespace <project-name> --apply\n    ```\n6.\tRun the following command to install Watson Knowledge Studio\n    ```\n    bin/cpd-Operating_System --repo wks-repo.yaml --assembly watson-ks --namespace <project-name> --transfer-image-to $(oc get route -n openshift-image-registry |tail -1|awk '{print $2}')/<project-name> --target-registry-username $(oc whoami) --target-registry-password $(oc whoami -t) --insecure-skip-tls-verify --cluster-pull-prefix image-registry.openshift-image-registry.svc:5000/<project-name> --storageclass ibmc-file-gold-gid\n    ```\n7.\tTo verify that the installation completed successfully, run the following command:\n    ```\n    bin/cpd-Operating_System status --assembly watson-ks --namespace <project-name>\n    ```\n8.\tProvision an instance of Watson Knowledge Studio\n\n    a.\tLog in to Cloud Pak for Data as an administrator.\n\n    b.\tFrom the toolbar, click the Services icon\n\n    c.\tFind the Watson Knowledge Studio service and ensure that it is Available.\n\n    d.\tFrom the action menu, select Provision instance.\n\n    e.\tGive Instance name and Click on Create.\n","fileAbsolutePath":"/home/runner/work/ibm-enterprise-runbooks/ibm-enterprise-runbooks/src/pages/install/data/index.mdx"}}},"staticQueryHashes":["1364590287","2102389209","2102389209","243517648","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","63531786","63531786","768070550","817386451"]}