{"componentChunkName":"component---src-pages-programming-cf-index-mdx","path":"/programming/cf/","result":{"pageContext":{"frontmatter":{"title":"IBM Cloud Functions and IBM Event Streams"},"relativePagePath":"/programming/cf/index.mdx","titleType":"page","MdxNode":{"id":"f336bdf8-a77b-55d9-a2ec-bee6d1265980","children":[],"parent":"0f021fc0-946c-5ccb-8f22-ead4051ae686","internal":{"content":"---\ntitle: IBM Cloud Functions and IBM Event Streams\n\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\n</PageDescription>\n\n## **Overview**\n\nSimple tutorial for reading IBM Event Streams (using Kafka) messages with IBM \nCloud Functions Python runtime.\n\n![Architecture Overview](images/overview-cf.png)\n\n<Tabs>\n\n<Tab label=\"Using IAM\" open=\"true\">\n\n## **Prerequisites**\n\n - An [IBM Cloud](https://cloud.ibm.com) account.\n\n## **Create an IBM Cloud Functions Namespace**.\n\n - First, let's create our [IBM Cloud Functions namespace](https://cloud.ibm.com/functions/actions) in which we are going to work:\n    ![Create new IBM Cloud Functions Namespace](images/fn-namespace-1.png)\n - Give it a name, select a resource group and region, then click **Create**:\n    ![Configure new IBM Cloud Functions Action](images/fn-namespace-2.png)\n\n## **Create an IBM Cloud Functions Action**\n\nCreate an [IBM Cloud Functions Action](https://cloud.ibm.com/functions/actions) called `process-message`, that uses the **Python** runtime:\n\n - Create a new Action\n    ![Create new IBM Cloud Functions Action](images/fn-actions-1.png)\n - Name it `process-message`, use default package, select **Python** runtime then click **Create**:\n    ![Configure new IBM Cloud Functions Action](images/fn-actions-2.png)\n - Put the following code inside the function:\n    ```python\n    def main(dict):\n        messages = dict.get('messages')\n\n        if messages is None or messages[0] is None:\n            return { 'error': \"Invalid arguments. Must include 'messages' JSON array\" }\n        try:\n            val = messages[0]['value']\n        except KeyError:\n            return { 'error': \"Invalid arguments. Must include 'messages' JSON array\" }\n\n        for i in range(0, len(messages)):\n            msg = messages[i]\n            print('Message received:', msg['value'])\n\n        return { 'messages': messages }\n    ```\n    ![Implement new IBM Cloud Functions Action](images/fn-actions-3.png)\n\n## **Provision IBM Event Streams**\n\n - Provision an [IBM Event Streams](https://cloud.ibm.com/catalog/services/event-streams) instance. In this tutorial I'll call IBM Event Streams service instance `my-event-streams`:\n    ![Provision IBM Event Streams](images/es-provision.png)\n - Once your service is created, create a new topic called `hello-world`:\n    ![Create new IBM Event Streams topic](images/es-create-topic.png)\n - Create service credentials called `cloud-functions`:\n    ![Create new IBM Event Streams service credentials](images/es-create-creds.png)\n - Save the `kafka_brokers_sasl`, `apikey` and `kafka_admin_url` values from the new credentials for future steps.\n\n## **Create a new Trigger for incoming messages on IBM Event Streams**\n\nCreate an [IBM Cloud Functions Trigger](https://cloud.ibm.com/functions/triggers) called `new-message-trigger`, that reacts to incoming Kafka messages on your `hello-world` topic of your `my-event-streams` IBM Event Streams instance:\n\n - Create the new trigger\n    ![Create new IBM Cloud Functions Trigger](images/fn-triggers-1.png)\n - Select `Trigger`\n    ![Select Trigger resource](images/fn-triggers-2.png)\n - Select `Event Streams` trigger type:\n    ![Select Event Streams trigger type](images/fn-triggers-3.png)\n - Set `new-message-trigger` as the name, `my-event-streams` as Event Streams instance, `hello-world` as the topic to watch:\n    ![Configure new IBM Cloud Functions Trigger](images/fn-triggers-4.png)\n - Bind your newly created trigger to your existing `process-message` action:\n    ![Bind Trigger to Action](images/fn-triggers-5.png)\n    ![Bind Trigger to Action](images/fn-triggers-6.png)\n\n</Tab>\n\n<Tab label=\"Using Cloud Foundry\">\n\n## **Prerequisites**\n\n- An [IBM Cloud](https://cloud.ibm.com) account.\n- [IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-getting-started).\n- [IBM Cloud Functions CLI](https://cloud.ibm.com/functions/learn/cli).\n- Cloud Foundry Organization (in this tutorial, I'll use `noe.samaille`).\n- Cloud Foundry Space (in this tutorial, I'll use is `test`).\n\n## **Log in to IBM Cloud using CLI**\n\n- Log in locally to your IBM Cloud account using the CLI:\n    ```\n    ibmcloud login\n    ```\n- Select your region (in this example I'll create resources in the `us-south` region):\n    ```\n    ibmcloud target -r us-south\n    ```\n- Select your resource group (in this example I'll use `default`):\n    ```\n    ibmcloud target -g default\n    ```\n- Select your Cloud Foundry org and space (in this example I'll use `noe.samaille` org and `test` space):\n    ```\n    ibmcloud target --cf\n    ```\n\n## **Create an IBM Cloud Functions Action**\n\nCreate an [IBM Cloud Functions Action](https://cloud.ibm.com/functions/actions) called `process-message`, that uses the **Python** runtime:\n\n - Create a new Action\n    ![Create new IBM Cloud Functions Action](images/fn-actions-1.png)\n - Name it `process-message`, use default package, select **Python** runtime then click **Create**:\n    ![Configure new IBM Cloud Functions Action](images/fn-actions-2.png)\n - Put the following code inside the function:\n    ```python\n    def main(dict):\n        messages = dict.get('messages')\n\n        if messages is None or messages[0] is None:\n            return { 'error': \"Invalid arguments. Must include 'messages' JSON array\" }\n        try:\n            val = messages[0]['value']\n        except KeyError:\n            return { 'error': \"Invalid arguments. Must include 'messages' JSON array\" }\n\n        for i in range(0, len(messages)):\n            msg = messages[i]\n            print('Message received:', msg['value'])\n\n        return { 'messages': messages }\n    ```\n    ![Implement new IBM Cloud Functions Action](images/fn-actions-3.png)\n\n## **Provision IBM Event Streams**\n\n - Provision an [IBM Event Streams](https://cloud.ibm.com/catalog/services/event-streams) instance. In this tutorial I'll call IBM Event Streams service instance `my-event-streams`:\n    ![Provision IBM Event Streams](images/es-provision.png)\n - Once your service is created, create a new topic called `hello-world`:\n    ![Create new IBM Event Streams topic](images/es-create-topic.png)\n - Create service credentials called `cloud-functions`:\n    ![Create new IBM Event Streams service credentials](images/es-create-creds.png)\n - Save the `kafka_brokers_sasl`, `apikey` and `kafka_admin_url` values from the new credentials for future steps.\n\n## **Binding the `/whisk.system/messaging` package to your Event Streams instance**\n\nMore information in the [documentation](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streams#event_streams_binding):\n\n- Create a `/whisk.system/messaging` package binding that is configured for your Event Streams account. In this example, the package name is `MyEventStreamBind`.\n    ```sh\n    ibmcloud fn package bind /whisk.system/messaging MyEventStreamBind\n    ```\n- Verify that the package binding exists.\n    ```sh\n    ibmcloud fn package list\n    ```\n- Get the name of the service instance that you want to bind to an action or package.\n    ```sh\n    ibmcloud resource service-instances\n    ```\n- Get the name of the credentials that are defined for the service instance you got in the previous step.\n    ```sh\n    ibmcloud resource service-keys --instance-name my-event-streams\n    ```\n- Bind the service to the package that you created in the first step. In the example, this package is called `MyEventStreamBind`.\n    ```sh\n    ibmcloud fn service bind messagehub MyEventStreamBind --instance my-event-streams --keyname cloud-functions\n    ```\n- Verify that the credentials are successfully bound.\n    ```sh\n    ibmcloud fn package get MyEventStreamBind parameters\n    ```\n- Create a trigger `new-message-trigger` that is fired when new messages are posted to your Event Streams topic.\n    ```sh\n    ibmcloud fn trigger create new-message-trigger -f /noe.samaille_test/MyEventStreamBind/MyEventStreamBind/messageHubFeed -p topic hello-world\n    ```\n\n## **Connect your action to the trigger**\n\n - On [IBM Cloud Functions Triggers](https://cloud.ibm.com/functions/triggers), click your newly created trigger `new-message-trigger`.\n - Bind your newly created trigger to your existing `process-message` action:\n    ![Bind Trigger to Action](images/fn-triggers-5.png)\n    ![Bind Trigger to Action](images/fn-triggers-6.png)\n\n</Tab>\n</Tabs>\n\n## **Test it out**\n\nNow let's try that our action is triggered by a new message on topic `hello-world`. Open a terminal for the next steps.\n\n - Clone event streams sample python client:\n    ```sh\n    git clone https://github.com/ibm-messaging/event-streams-samples\n    cd event-streams-samples/kafka-python-console-sample\n    ```\n - In `event-streams-samples/kafka-python-console-sample/app.py`, replace:\n    ```python\n    self.topic_name = 'kafka-python-console-sample-topic'\n    ```\n    With:\n    ```python\n    self.topic_name = 'hello-world'\n    ```\n - Run producer (use the values you copied from your Event Streams credentials, check [how to set up environment config](https://github.com/ibm-messaging/event-streams-samples/blob/master/kafka-python-console-sample/docs/Local.md) for more information):\n    ```sh\n    export KAFKA_BROKERS=<KAFKA_BROKERS>\n    export KAFKA_ADMIN_URL=<KAFKA_ADMIN_URL>\n    export KAFKA_APIKEY=<KAFKA_APIKEY>\n    python3 app.py $KAFKA_BROKERS $KAFKA_ADMIN_URL $KAFKA_APIKEY ../../certs.pem -producer\n    ```\n - Open the [IBM Cloud Functions Activations Dashboard](https://cloud.ibm.com/functions/dashboard), you should see your action activated at each new message.\n    ![IBM Cloud Functions activations](images/fn-activations-1.png)\n    - If you click on an activation hash, you should see the test messages in the function's output.\n    - **NOTE**: The first activation takes more time and may handle several messages at once, since the action is cold. See the [Docs](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-about) for more information.\n\n## **Enable logging with LogDNA**\n\n - Provision a new [IBM Log Analysis with LogDNA](https://cloud.ibm.com/catalog/services/logdna) instance. \n    ![Provision LogDNA](images/logdna-1.png)\n - In [IBM Cloud Logging Dashboard](https://cloud.ibm.com/observe/logging), click **Configure platform logs**. \n    ![Provision LogDNA](images/logdna-3.png)\n - Enable your LogDNA instance to handle platform logs. \n    ![Provision LogDNA](images/logdna-4.png)\n\nThere you are, your LogDNA instance now retrieves logs from your IBM Cloud Functions activations!","type":"Mdx","contentDigest":"71563640688f25663feae67e0f58fe4d","counter":961,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"IBM Cloud Functions and IBM Event Streams"},"exports":{},"rawBody":"---\ntitle: IBM Cloud Functions and IBM Event Streams\n\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\n</PageDescription>\n\n## **Overview**\n\nSimple tutorial for reading IBM Event Streams (using Kafka) messages with IBM \nCloud Functions Python runtime.\n\n![Architecture Overview](images/overview-cf.png)\n\n<Tabs>\n\n<Tab label=\"Using IAM\" open=\"true\">\n\n## **Prerequisites**\n\n - An [IBM Cloud](https://cloud.ibm.com) account.\n\n## **Create an IBM Cloud Functions Namespace**.\n\n - First, let's create our [IBM Cloud Functions namespace](https://cloud.ibm.com/functions/actions) in which we are going to work:\n    ![Create new IBM Cloud Functions Namespace](images/fn-namespace-1.png)\n - Give it a name, select a resource group and region, then click **Create**:\n    ![Configure new IBM Cloud Functions Action](images/fn-namespace-2.png)\n\n## **Create an IBM Cloud Functions Action**\n\nCreate an [IBM Cloud Functions Action](https://cloud.ibm.com/functions/actions) called `process-message`, that uses the **Python** runtime:\n\n - Create a new Action\n    ![Create new IBM Cloud Functions Action](images/fn-actions-1.png)\n - Name it `process-message`, use default package, select **Python** runtime then click **Create**:\n    ![Configure new IBM Cloud Functions Action](images/fn-actions-2.png)\n - Put the following code inside the function:\n    ```python\n    def main(dict):\n        messages = dict.get('messages')\n\n        if messages is None or messages[0] is None:\n            return { 'error': \"Invalid arguments. Must include 'messages' JSON array\" }\n        try:\n            val = messages[0]['value']\n        except KeyError:\n            return { 'error': \"Invalid arguments. Must include 'messages' JSON array\" }\n\n        for i in range(0, len(messages)):\n            msg = messages[i]\n            print('Message received:', msg['value'])\n\n        return { 'messages': messages }\n    ```\n    ![Implement new IBM Cloud Functions Action](images/fn-actions-3.png)\n\n## **Provision IBM Event Streams**\n\n - Provision an [IBM Event Streams](https://cloud.ibm.com/catalog/services/event-streams) instance. In this tutorial I'll call IBM Event Streams service instance `my-event-streams`:\n    ![Provision IBM Event Streams](images/es-provision.png)\n - Once your service is created, create a new topic called `hello-world`:\n    ![Create new IBM Event Streams topic](images/es-create-topic.png)\n - Create service credentials called `cloud-functions`:\n    ![Create new IBM Event Streams service credentials](images/es-create-creds.png)\n - Save the `kafka_brokers_sasl`, `apikey` and `kafka_admin_url` values from the new credentials for future steps.\n\n## **Create a new Trigger for incoming messages on IBM Event Streams**\n\nCreate an [IBM Cloud Functions Trigger](https://cloud.ibm.com/functions/triggers) called `new-message-trigger`, that reacts to incoming Kafka messages on your `hello-world` topic of your `my-event-streams` IBM Event Streams instance:\n\n - Create the new trigger\n    ![Create new IBM Cloud Functions Trigger](images/fn-triggers-1.png)\n - Select `Trigger`\n    ![Select Trigger resource](images/fn-triggers-2.png)\n - Select `Event Streams` trigger type:\n    ![Select Event Streams trigger type](images/fn-triggers-3.png)\n - Set `new-message-trigger` as the name, `my-event-streams` as Event Streams instance, `hello-world` as the topic to watch:\n    ![Configure new IBM Cloud Functions Trigger](images/fn-triggers-4.png)\n - Bind your newly created trigger to your existing `process-message` action:\n    ![Bind Trigger to Action](images/fn-triggers-5.png)\n    ![Bind Trigger to Action](images/fn-triggers-6.png)\n\n</Tab>\n\n<Tab label=\"Using Cloud Foundry\">\n\n## **Prerequisites**\n\n- An [IBM Cloud](https://cloud.ibm.com) account.\n- [IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-getting-started).\n- [IBM Cloud Functions CLI](https://cloud.ibm.com/functions/learn/cli).\n- Cloud Foundry Organization (in this tutorial, I'll use `noe.samaille`).\n- Cloud Foundry Space (in this tutorial, I'll use is `test`).\n\n## **Log in to IBM Cloud using CLI**\n\n- Log in locally to your IBM Cloud account using the CLI:\n    ```\n    ibmcloud login\n    ```\n- Select your region (in this example I'll create resources in the `us-south` region):\n    ```\n    ibmcloud target -r us-south\n    ```\n- Select your resource group (in this example I'll use `default`):\n    ```\n    ibmcloud target -g default\n    ```\n- Select your Cloud Foundry org and space (in this example I'll use `noe.samaille` org and `test` space):\n    ```\n    ibmcloud target --cf\n    ```\n\n## **Create an IBM Cloud Functions Action**\n\nCreate an [IBM Cloud Functions Action](https://cloud.ibm.com/functions/actions) called `process-message`, that uses the **Python** runtime:\n\n - Create a new Action\n    ![Create new IBM Cloud Functions Action](images/fn-actions-1.png)\n - Name it `process-message`, use default package, select **Python** runtime then click **Create**:\n    ![Configure new IBM Cloud Functions Action](images/fn-actions-2.png)\n - Put the following code inside the function:\n    ```python\n    def main(dict):\n        messages = dict.get('messages')\n\n        if messages is None or messages[0] is None:\n            return { 'error': \"Invalid arguments. Must include 'messages' JSON array\" }\n        try:\n            val = messages[0]['value']\n        except KeyError:\n            return { 'error': \"Invalid arguments. Must include 'messages' JSON array\" }\n\n        for i in range(0, len(messages)):\n            msg = messages[i]\n            print('Message received:', msg['value'])\n\n        return { 'messages': messages }\n    ```\n    ![Implement new IBM Cloud Functions Action](images/fn-actions-3.png)\n\n## **Provision IBM Event Streams**\n\n - Provision an [IBM Event Streams](https://cloud.ibm.com/catalog/services/event-streams) instance. In this tutorial I'll call IBM Event Streams service instance `my-event-streams`:\n    ![Provision IBM Event Streams](images/es-provision.png)\n - Once your service is created, create a new topic called `hello-world`:\n    ![Create new IBM Event Streams topic](images/es-create-topic.png)\n - Create service credentials called `cloud-functions`:\n    ![Create new IBM Event Streams service credentials](images/es-create-creds.png)\n - Save the `kafka_brokers_sasl`, `apikey` and `kafka_admin_url` values from the new credentials for future steps.\n\n## **Binding the `/whisk.system/messaging` package to your Event Streams instance**\n\nMore information in the [documentation](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streams#event_streams_binding):\n\n- Create a `/whisk.system/messaging` package binding that is configured for your Event Streams account. In this example, the package name is `MyEventStreamBind`.\n    ```sh\n    ibmcloud fn package bind /whisk.system/messaging MyEventStreamBind\n    ```\n- Verify that the package binding exists.\n    ```sh\n    ibmcloud fn package list\n    ```\n- Get the name of the service instance that you want to bind to an action or package.\n    ```sh\n    ibmcloud resource service-instances\n    ```\n- Get the name of the credentials that are defined for the service instance you got in the previous step.\n    ```sh\n    ibmcloud resource service-keys --instance-name my-event-streams\n    ```\n- Bind the service to the package that you created in the first step. In the example, this package is called `MyEventStreamBind`.\n    ```sh\n    ibmcloud fn service bind messagehub MyEventStreamBind --instance my-event-streams --keyname cloud-functions\n    ```\n- Verify that the credentials are successfully bound.\n    ```sh\n    ibmcloud fn package get MyEventStreamBind parameters\n    ```\n- Create a trigger `new-message-trigger` that is fired when new messages are posted to your Event Streams topic.\n    ```sh\n    ibmcloud fn trigger create new-message-trigger -f /noe.samaille_test/MyEventStreamBind/MyEventStreamBind/messageHubFeed -p topic hello-world\n    ```\n\n## **Connect your action to the trigger**\n\n - On [IBM Cloud Functions Triggers](https://cloud.ibm.com/functions/triggers), click your newly created trigger `new-message-trigger`.\n - Bind your newly created trigger to your existing `process-message` action:\n    ![Bind Trigger to Action](images/fn-triggers-5.png)\n    ![Bind Trigger to Action](images/fn-triggers-6.png)\n\n</Tab>\n</Tabs>\n\n## **Test it out**\n\nNow let's try that our action is triggered by a new message on topic `hello-world`. Open a terminal for the next steps.\n\n - Clone event streams sample python client:\n    ```sh\n    git clone https://github.com/ibm-messaging/event-streams-samples\n    cd event-streams-samples/kafka-python-console-sample\n    ```\n - In `event-streams-samples/kafka-python-console-sample/app.py`, replace:\n    ```python\n    self.topic_name = 'kafka-python-console-sample-topic'\n    ```\n    With:\n    ```python\n    self.topic_name = 'hello-world'\n    ```\n - Run producer (use the values you copied from your Event Streams credentials, check [how to set up environment config](https://github.com/ibm-messaging/event-streams-samples/blob/master/kafka-python-console-sample/docs/Local.md) for more information):\n    ```sh\n    export KAFKA_BROKERS=<KAFKA_BROKERS>\n    export KAFKA_ADMIN_URL=<KAFKA_ADMIN_URL>\n    export KAFKA_APIKEY=<KAFKA_APIKEY>\n    python3 app.py $KAFKA_BROKERS $KAFKA_ADMIN_URL $KAFKA_APIKEY ../../certs.pem -producer\n    ```\n - Open the [IBM Cloud Functions Activations Dashboard](https://cloud.ibm.com/functions/dashboard), you should see your action activated at each new message.\n    ![IBM Cloud Functions activations](images/fn-activations-1.png)\n    - If you click on an activation hash, you should see the test messages in the function's output.\n    - **NOTE**: The first activation takes more time and may handle several messages at once, since the action is cold. See the [Docs](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-about) for more information.\n\n## **Enable logging with LogDNA**\n\n - Provision a new [IBM Log Analysis with LogDNA](https://cloud.ibm.com/catalog/services/logdna) instance. \n    ![Provision LogDNA](images/logdna-1.png)\n - In [IBM Cloud Logging Dashboard](https://cloud.ibm.com/observe/logging), click **Configure platform logs**. \n    ![Provision LogDNA](images/logdna-3.png)\n - Enable your LogDNA instance to handle platform logs. \n    ![Provision LogDNA](images/logdna-4.png)\n\nThere you are, your LogDNA instance now retrieves logs from your IBM Cloud Functions activations!","fileAbsolutePath":"/home/runner/work/ibm-enterprise-runbooks/ibm-enterprise-runbooks/src/pages/programming/cf/index.mdx"}}},"staticQueryHashes":["1364590287","2102389209","2102389209","243517648","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","63531786","63531786","768070550","817386451"]}